## Case studies for ordered normative restraining bolts

The enclosed Python code can be used to reproduce the case studies utilized in "Combining MORL with Restraining Bolts to Learn Normative Behaviour".

You can find the agent used, **MORLRBNormAgent**, in ``qlLTL.py``, and the CHVI and weight computationa in ``CHVI.py`` and ``weight_computation.py`` respectively. The code required to generate the results given in Section 5 of our paper can be found in the folder **experiments**, and if you just want to see the results, you can examine the subfolder **/experiments/results**, which contains the graph generated by ``generate_graph.py`` and the agent trajectories for each agent generarated by the identically named .py files in **experiments**.


### Reproducing results

You will need Python 3 to run the code in this folder, and you will need the following packages:

- NumPy
- Matplotlib
- SciPy
- Python-MIP

To compute the weights for each case study, run:

``python3 compute_w_<dilemma/ctd/permission.>.py``

The weights will be printed in the console. Note that weights need to be rounded *up*.

To run the RL algorithm, you can run:

``python3 test_<dilemma/ctd/norm_revision>.py``

The trajectory will be saved in a timestamped .csv files.


#### Warning

Take caution when running ``compute_w_dilemma.py``. The fact that more actions are available to the agent in this case study due to removed restrictions on the environment means that CHVI becomes very computationally expensive. It requires >100 GB RAM, and will take 2-3 hours. However, for every iteration of the CHVI algorithm, the hull of the initial state is printed in the console, so you can still watch how the hull evolves for a number of iterations.


